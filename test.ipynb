{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOf/oky9dx73m5VYYGYSluD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sima97/unihobby/blob/master/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHuY1FGnnV-s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "51a3a4bc-0173-4f23-9b1d-e67ff6b610f4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLY1CBX8ncZm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "28d14142-ce49-4a6d-ac97-52ad10463841"
      },
      "source": [
        "pip install nilearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nilearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/c2/f5f1bdd37a3da28b3b34305e4ba27cce468db6073998d62a38abd0e281da/nilearn-0.6.2-py3-none-any.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: nibabel>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from nilearn) (3.0.2)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.6/dist-packages (from nilearn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from nilearn) (0.16.0)\n",
            "Requirement already satisfied: scikit-learn>=0.19 in /usr/local/lib/python3.6/dist-packages (from nilearn) (0.22.2.post1)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from nilearn) (0.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from nilearn) (1.18.5)\n",
            "Installing collected packages: nilearn\n",
            "Successfully installed nilearn-0.6.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvgr0CEWncxJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "fd3d5b7e-0157-4108-ccc9-ad1b49ff11b3"
      },
      "source": [
        "pip install tables"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tables in /usr/local/lib/python3.6/dist-packages (3.4.4)\n",
            "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from tables) (1.18.5)\n",
            "Requirement already satisfied: numexpr>=2.5.2 in /usr/local/lib/python3.6/dist-packages (from tables) (2.7.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from tables) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFTUXEL-oxEO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "9bf7349f-f4ec-4587-a22f-3d0a651401b3"
      },
      "source": [
        "pip install git+https://www.github.com/farizrahman4u/keras-contrib.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://www.github.com/farizrahman4u/keras-contrib.git\n",
            "  Cloning https://www.github.com/farizrahman4u/keras-contrib.git to /tmp/pip-req-build-yzohelfu\n",
            "  Running command git clone -q https://www.github.com/farizrahman4u/keras-contrib.git /tmp/pip-req-build-yzohelfu\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8) (2.4.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras->keras-contrib==2.0.8) (1.15.0)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp36-none-any.whl size=101064 sha256=50102c03bf897ccffa1d047fe537ea0faf3e58faaaebb788a0a926f266d294f4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ti7rwgth/wheels/1f/8e/ac/fb1cca9d92276d64365b204e82a9a5bec1f24a20aca28fdbec\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhM_vQjLoxNm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "0d01bd78-8f43-4b13-d861-7aa1b0e06267"
      },
      "source": [
        "pip install SimpleITK "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting SimpleITK\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/d8/53338c34f71020725ffb3557846c80af96c29c03bc883551a2565aa68a7c/SimpleITK-1.2.4-cp36-cp36m-manylinux1_x86_64.whl (42.5MB)\n",
            "\u001b[K     |████████████████████████████████| 42.5MB 98kB/s \n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-1.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVChUL9rqlH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pip install tensorflow==1.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRBzH8L-pmQj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "ad666c3f-54d4-47da-b340-163c138189d8"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior() \n",
        "\n",
        "def cross_entropy_loss_v1(y_true, y_pred, sample_weight=None, eps=1e-6):\n",
        "    \"\"\"\n",
        "    :param y_pred: output 5D tensor, [batch size, dim0, dim1, dim2, class]\n",
        "    :param y_true: 4D GT tensor, [batch size, dim0, dim1, dim2]\n",
        "    :param eps: avoid log0\n",
        "    :return: cross entropy loss\n",
        "    \"\"\"\n",
        "    log_y = tf.log(y_pred + eps)\n",
        "    num_samples = tf.cast(tf.reduce_prod(tf.shape(y_true)), \"float32\")\n",
        "    label_one_hot = tf.one_hot(indices=y_true, depth=y_pred.shape[-1], axis=-1, dtype=tf.float32)\n",
        "    if sample_weight is not None:\n",
        "        # ce = mean(- weight * y_true * log(y_pred)).\n",
        "        label_one_hot = label_one_hot * sample_weight\n",
        "    cross_entropy = - tf.reduce_sum(label_one_hot * log_y) / num_samples\n",
        "    return cross_entropy\n",
        "\n",
        "\n",
        "def cross_entropy_loss(y_true, y_pred, sample_weight=None):\n",
        "    # may not use one_hot when use tf.keras.losses.CategoricalCrossentropy\n",
        "    y_true = tf.one_hot(indices=y_true, depth=y_pred.shape[-1], axis=-1, dtype=tf.float32)\n",
        "    if sample_weight is not None:\n",
        "        # ce = mean(weight * y_true * log(y_pred)).\n",
        "        y_true = y_true * sample_weight\n",
        "    return tf.keras.losses.BinaryCrossentropy()(y_true, y_pred)\n",
        "\n",
        "\n",
        "def cross_entropy_loss_with_weight(y_true, y_pred, sample_weight_per_c=None, eps=1e-6):\n",
        "    # for simple calculate this batch.\n",
        "    # if possible, get weight per epoch before training.\n",
        "    num_dims, num_classes = [len(y_true.shape), y_pred.shape.as_list()[-1]]\n",
        "    if sample_weight_per_c is None:\n",
        "        print('use batch to calculate weight')\n",
        "        num_lbls_in_ygt = tf.cast(tf.reduce_prod(tf.shape(y_true)), dtype=\"float32\")\n",
        "        num_lbls_in_ygt_per_c = tf.bincount(arr=tf.cast(y_true, tf.int32), minlength=num_classes, maxlength=num_classes,\n",
        "                                            dtype=\"float32\")  # without the min/max, length of vector can change.\n",
        "        sample_weight_per_c = (1. / (num_lbls_in_ygt_per_c + eps)) * (num_lbls_in_ygt / num_classes)\n",
        "    sample_weight_per_c = tf.reshape(sample_weight_per_c, [1] * num_dims + [num_classes])\n",
        "    # use cross_entropy_loss get negative value, while cross_entropy_loss and cross_entropy_loss_v1 get the same\n",
        "    # when no weight. I guess may some error when batch distribution is huge different from epoch distribution.\n",
        "    return cross_entropy_loss_v1(y_true, y_pred, sample_weight=sample_weight_per_c)\n",
        "\n",
        "\n",
        "def dice_coef(y_true, y_pred, eps=1e-6):\n",
        "    # problem: when gt class-0 >> class-1, the pred p(class-0) >> p(class-1)\n",
        "    # eg. gt = [0, 0, 0, 0, 1] pred = [[1, 0], [1, 0], [1, 0], [1, 0], [1, 0]]. 2 * 4 / (5 + 5) = 0.8\n",
        "    # in fact, change every pred, 4/5 -> 0.6, 1/5 ->1, so the model just pred all 0. imbalance class problem.\n",
        "    # only calculate gt == 1 can fix my problem, but for multi-class task, weight needed like ce loss above.\n",
        "    y_true = tf.one_hot(indices=y_true, depth=y_pred.shape[-1], axis=-1, dtype=tf.float32)\n",
        "    abs_x_and_y = 2 * tf.reduce_sum(y_true * y_pred)\n",
        "    abs_x_plus_abs_y = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)\n",
        "    return (abs_x_and_y + eps) / (abs_x_plus_abs_y + eps)\n",
        "\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return 1. - dice_coef(y_true, y_pred)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "0.109087184\n",
            "0.10908617\n",
            "use batch to calculate weight\n",
            "0.107429765\n",
            "0.10195482\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVHDD6Rt029X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras import backend as K\n",
        "from keras.engine import Input, Model\n",
        "from keras.layers import Conv3D, MaxPooling3D, UpSampling3D, Activation, BatchNormalization, PReLU#, Deconvolution3D\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "#from unet3d.metrics import dice_coefficient_loss, get_label_dice_coefficient_function, dice_coefficient\n",
        "\n",
        "K.set_image_data_format(\"channels_first\")\n",
        "\n",
        "try:\n",
        "    from keras.engine import merge\n",
        "except ImportError:\n",
        "    from keras.layers.merge import concatenate\n",
        "\n",
        "\n",
        "def unet_model_3d(input_shape, pool_size=(2, 2, 2), n_labels=1, initial_learning_rate=0.00001, deconvolution=False,\n",
        "                  depth=4, n_base_filters=32, include_label_wise_dice_coefficients=False, metrics=dice_coef,\n",
        "                  batch_normalization=False, activation_name=\"sigmoid\"):\n",
        "    \"\"\"\n",
        "    Builds the 3D UNet Keras model.f\n",
        "    :param metrics: List metrics to be calculated during model training (default is dice coefficient).\n",
        "    :param include_label_wise_dice_coefficients: If True and n_labels is greater than 1, model will report the dice\n",
        "    coefficient for each label as metric.\n",
        "    :param n_base_filters: The number of filters that the first layer in the convolution network will have. Following\n",
        "    layers will contain a multiple of this number. Lowering this number will likely reduce the amount of memory required\n",
        "    to train the model.\n",
        "    :param depth: indicates the depth of the U-shape for the model. The greater the depth, the more max pooling\n",
        "    layers will be added to the model. Lowering the depth may reduce the amount of memory required for training.\n",
        "    :param input_shape: Shape of the input data (n_chanels, x_size, y_size, z_size). The x, y, and z sizes must be\n",
        "    divisible by the pool size to the power of the depth of the UNet, that is pool_size^depth.\n",
        "    :param pool_size: Pool size for the max pooling operations.\n",
        "    :param n_labels: Number of binary labels that the model is learning.\n",
        "    :param initial_learning_rate: Initial learning rate for the model. This will be decayed during training.\n",
        "    :param deconvolution: If set to True, will use transpose convolution(deconvolution) instead of up-sampling. This\n",
        "    increases the amount memory required during training.\n",
        "    :return: Untrained 3D UNet Model\n",
        "    \"\"\"\n",
        "    inputs = Input(input_shape)\n",
        "    current_layer = inputs\n",
        "    levels = list()\n",
        "\n",
        "    # add levels with max pooling\n",
        "    for layer_depth in range(depth):\n",
        "        layer1 = create_convolution_block(input_layer=current_layer, n_filters=n_base_filters*(2**layer_depth),\n",
        "                                          batch_normalization=batch_normalization)\n",
        "        layer2 = create_convolution_block(input_layer=layer1, n_filters=n_base_filters*(2**layer_depth)*2,\n",
        "                                          batch_normalization=batch_normalization)\n",
        "        if layer_depth < depth - 1:\n",
        "            current_layer = MaxPooling3D(pool_size=pool_size)(layer2)\n",
        "            levels.append([layer1, layer2, current_layer])\n",
        "        else:\n",
        "            current_layer = layer2\n",
        "            levels.append([layer1, layer2])\n",
        "\n",
        "    # add levels with up-convolution or up-sampling\n",
        "    for layer_depth in range(depth-2, -1, -1):\n",
        "        up_convolution = get_up_convolution(pool_size=pool_size, deconvolution=deconvolution,\n",
        "                                            n_filters=current_layer._keras_shape[1])(current_layer)\n",
        "        concat = concatenate([up_convolution, levels[layer_depth][1]], axis=1)\n",
        "        current_layer = create_convolution_block(n_filters=levels[layer_depth][1]._keras_shape[1],\n",
        "                                                 input_layer=concat, batch_normalization=batch_normalization)\n",
        "        current_layer = create_convolution_block(n_filters=levels[layer_depth][1]._keras_shape[1],\n",
        "                                                 input_layer=current_layer,\n",
        "                                                 batch_normalization=batch_normalization)\n",
        "\n",
        "    final_convolution = Conv3D(n_labels, (1, 1, 1))(current_layer)\n",
        "    act = Activation(activation_name)(final_convolution)\n",
        "    model = Model(inputs=inputs, outputs=act)\n",
        "\n",
        "    if not isinstance(metrics, list):\n",
        "        metrics = [metrics]\n",
        "\n",
        "    if include_label_wise_dice_coefficients and n_labels > 1:\n",
        "        label_wise_dice_metrics = [get_label_dice_coefficient_function(index) for index in range(n_labels)]\n",
        "        if metrics:\n",
        "            metrics = metrics + label_wise_dice_metrics\n",
        "        else:\n",
        "            metrics = label_wise_dice_metrics\n",
        "\n",
        "    model.compile(optimizer=Adam(lr=initial_learning_rate), loss=dice_coefficient_loss, metrics=metrics)\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_convolution_block(input_layer, n_filters, batch_normalization=False, kernel=(3, 3, 3), activation=None,\n",
        "                             padding='same', strides=(1, 1, 1), instance_normalization=False):\n",
        "    \"\"\"\n",
        "    :param strides:\n",
        "    :param input_layer:\n",
        "    :param n_filters:\n",
        "    :param batch_normalization:\n",
        "    :param kernel:\n",
        "    :param activation: Keras activation layer to use. (default is 'relu')\n",
        "    :param padding:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    layer = Conv3D(n_filters, kernel, padding=padding, strides=strides)(input_layer)\n",
        "    if batch_normalization:\n",
        "        layer = BatchNormalization(axis=1)(layer)\n",
        "    elif instance_normalization:\n",
        "        try:\n",
        "           from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
        "        except ImportError:\n",
        "            raise ImportError(\"Install keras_contrib in order to use instance normalization.\"\n",
        "                              \"\\nTry: pip install git+https://www.github.com/farizrahman4u/keras-contrib.git\")\n",
        "        layer = InstanceNormalization(axis=1)(layer)\n",
        "    if activation is None:\n",
        "        return Activation('relu')(layer)\n",
        "    else:\n",
        "        return activation()(layer)\n",
        "\n",
        "\n",
        "def compute_level_output_shape(n_filters, depth, pool_size, image_shape):\n",
        "    \"\"\"\n",
        "    Each level has a particular output shape based on the number of filters used in that level and the depth or number \n",
        "    of max pooling operations that have been done on the data at that point.\n",
        "    :param image_shape: shape of the 3d image.\n",
        "    :param pool_size: the pool_size parameter used in the max pooling operation.\n",
        "    :param n_filters: Number of filters used by the last node in a given level.\n",
        "    :param depth: The number of levels down in the U-shaped model a given node is.\n",
        "    :return: 5D vector of the shape of the output node \n",
        "    \"\"\"\n",
        "    output_image_shape = np.asarray(np.divide(image_shape, np.power(pool_size, depth)), dtype=np.int32).tolist()\n",
        "    return tuple([None, n_filters] + output_image_shape)\n",
        "\n",
        "\n",
        "def get_up_convolution(n_filters, pool_size, kernel_size=(2, 2, 2), strides=(2, 2, 2),\n",
        "                       deconvolution=False):\n",
        "    if deconvolution:\n",
        "        return Deconvolution3D(filters=n_filters, kernel_size=kernel_size,\n",
        "                               strides=strides)\n",
        "    else:\n",
        "        return UpSampling3D(size=pool_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMy-CypSpmDI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "outputId": "c49c6fc2-5f95-4476-8ca2-62efb187bc35"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "#from unet3d.data import write_data_to_file, open_data_file\n",
        "#from unet3d.generator import get_training_and_validation_generators\n",
        "#from unet3d.model import unet_model_3d\n",
        "#from unet3d.training import load_old_model, train_model\n",
        "\n",
        "\n",
        "config = dict()\n",
        "config[\"pool_size\"] = (2, 2, 2)  # pool size for the max pooling operations\n",
        "config[\"image_shape\"] = (144, 144, 144)  # This determines what shape the images will be cropped/resampled to.\n",
        "config[\"patch_shape\"] = (64, 64, 64)  # switch to None to train on the whole image\n",
        "config[\"labels\"] = (1, 2, 4)  # the label numbers on the input image\n",
        "config[\"n_labels\"] = len(config[\"labels\"])\n",
        "config[\"all_modalities\"] = [\"t1\", \"t1ce\", \"flair\", \"t2\"]\n",
        "config[\"training_modalities\"] = config[\"all_modalities\"]  # change this if you want to only use some of the modalities\n",
        "config[\"nb_channels\"] = len(config[\"training_modalities\"])\n",
        "if \"patch_shape\" in config and config[\"patch_shape\"] is not None:\n",
        "    config[\"input_shape\"] = tuple([config[\"nb_channels\"]] + list(config[\"patch_shape\"]))\n",
        "else:\n",
        "    config[\"input_shape\"] = tuple([config[\"nb_channels\"]] + list(config[\"image_shape\"]))\n",
        "config[\"truth_channel\"] = config[\"nb_channels\"]\n",
        "config[\"deconvolution\"] = True  # if False, will use upsampling instead of deconvolution\n",
        "\n",
        "config[\"batch_size\"] = 6\n",
        "config[\"validation_batch_size\"] = 12\n",
        "config[\"n_epochs\"] = 500  # cutoff the training after this many epochs\n",
        "config[\"patience\"] = 10  # learning rate will be reduced after this many epochs if the validation loss is not improving\n",
        "config[\"early_stop\"] = 50  # training will be stopped after this many epochs without the validation loss improving\n",
        "config[\"initial_learning_rate\"] = 0.00001\n",
        "config[\"learning_rate_drop\"] = 0.5  # factor by which the learning rate will be reduced\n",
        "config[\"validation_split\"] = 0.8  # portion of the data that will be used for training\n",
        "config[\"flip\"] = False  # augments the data by randomly flipping an axis during\n",
        "config[\"permute\"] = True  # data shape must be a cube. Augments the data by permuting in various directions\n",
        "config[\"distort\"] = None  # switch to None if you want no distortion\n",
        "config[\"augment\"] = config[\"flip\"] or config[\"distort\"]\n",
        "config[\"validation_patch_overlap\"] = 0  # if > 0, during training, validation patches will be overlapping\n",
        "config[\"training_patch_start_offset\"] = (16, 16, 16)  # randomly offset the first patch index by up to this offset\n",
        "config[\"skip_blank\"] = True  # if True, then patches without any target will be skipped\n",
        "\n",
        "config[\"data_file\"] = os.path.abspath(\"/content/drive/My Drive/Brats2019/data.h5\")\n",
        "config[\"model_file\"] = os.path.abspath(\"/content/drive/My Drive/Brats2019/tumor_segmentation_model.h5\")\n",
        "config[\"training_file\"] = os.path.abspath(\"/content/drive/My Drive/Brats2019/pkl/training_ids.pkl\")\n",
        "config[\"validation_file\"] = os.path.abspath(\"/content/drive/My Drive/Brats2019/pkl/validation_ids.pkl\")\n",
        "config[\"overwrite\"] = False  # If True, will previous files. If False, will use previously written files.\n",
        "\n",
        "\n",
        "def fetch_training_data_files():\n",
        "    training_data_files = list()\n",
        "    for subject_dir in glob.glob(os.path.join(os.path.dirname(__file__), \"data\", \"preprocessed\", \"*\", \"*\")):\n",
        "        subject_files = list()\n",
        "        for modality in config[\"training_modalities\"] + [\"truth\"]:\n",
        "            subject_files.append(os.path.join(subject_dir, modality + \".nii.gz\"))\n",
        "        training_data_files.append(tuple(subject_files))\n",
        "    return training_data_files\n",
        "\n",
        "\n",
        "def main(overwrite=False):\n",
        "    # convert input images into an hdf5 file\n",
        "    if overwrite or not os.path.exists(config[\"data_file\"]):\n",
        "        training_files = fetch_training_data_files()\n",
        "\n",
        "        write_data_to_file(training_files, config[\"data_file\"], image_shape=config[\"image_shape\"])\n",
        "    data_file_opened = open_data_file(config[\"data_file\"])\n",
        "\n",
        "    if not overwrite and os.path.exists(config[\"model_file\"]):\n",
        "        model = load_old_model(config[\"model_file\"])\n",
        "    else:\n",
        "        # instantiate new model\n",
        "        model = unet_model_3d(input_shape=config[\"input_shape\"],\n",
        "                              pool_size=config[\"pool_size\"],\n",
        "                              n_labels=config[\"n_labels\"],\n",
        "                              initial_learning_rate=config[\"initial_learning_rate\"],\n",
        "                              deconvolution=config[\"deconvolution\"])\n",
        "\n",
        "    # get training and testing generators\n",
        "    train_generator, validation_generator, n_train_steps, n_validation_steps = get_training_and_validation_generators(\n",
        "        data_file_opened,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "        data_split=config[\"validation_split\"],\n",
        "        overwrite=overwrite,\n",
        "        validation_keys_file=config[\"validation_file\"],\n",
        "        training_keys_file=config[\"training_file\"],\n",
        "        n_labels=config[\"n_labels\"],\n",
        "        labels=config[\"labels\"],\n",
        "        patch_shape=config[\"patch_shape\"],\n",
        "        validation_batch_size=config[\"validation_batch_size\"],\n",
        "        validation_patch_overlap=config[\"validation_patch_overlap\"],\n",
        "        training_patch_start_offset=config[\"training_patch_start_offset\"],\n",
        "        permute=config[\"permute\"],\n",
        "        augment=config[\"augment\"],\n",
        "        skip_blank=config[\"skip_blank\"],\n",
        "        augment_flip=config[\"flip\"],\n",
        "        augment_distortion_factor=config[\"distort\"])\n",
        "\n",
        "    # run training\n",
        "    train_model(model=model,\n",
        "                model_file=config[\"model_file\"],\n",
        "                training_generator=train_generator,\n",
        "                validation_generator=validation_generator,\n",
        "                steps_per_epoch=n_train_steps,\n",
        "                validation_steps=n_validation_steps,\n",
        "                initial_learning_rate=config[\"initial_learning_rate\"],\n",
        "                learning_rate_drop=config[\"learning_rate_drop\"],\n",
        "                learning_rate_patience=config[\"patience\"],\n",
        "                early_stopping_patience=config[\"early_stop\"],\n",
        "                n_epochs=config[\"n_epochs\"])\n",
        "    data_file_opened.close()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main(overwrite=config[\"overwrite\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-20ec5b2c3dd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"overwrite\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-20ec5b2c3dd8>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(overwrite)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# convert input images into an hdf5 file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moverwrite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data_file\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mtraining_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_training_data_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mwrite_data_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data_file\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image_shape\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-20ec5b2c3dd8>\u001b[0m in \u001b[0;36mfetch_training_data_files\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfetch_training_data_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mtraining_data_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0msubject_dir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"preprocessed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"*\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0msubject_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodality\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"training_modalities\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"truth\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data_file' is not defined"
          ]
        }
      ]
    }
  ]
}